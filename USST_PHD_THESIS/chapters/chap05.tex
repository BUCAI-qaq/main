\title{面向任意姿态跌倒恢复的绳驱动双足自适应起身控制}
提出一种范式

我现在在写我的大论文的第5章，第4章我已经写了基于模仿的双足机器人全身控制。在第五章我想更深入的研究，主要内容是将全身控制进行扩展，实现绳驱动双足任意姿态摔倒爬起，和坐起内容。主要方法是首先将起身任务拆分为两个阶段：阶段一：训练任意姿势过渡到起身的初始姿态；阶段二利用第四章的全身控制框架训练起身，阶段一和阶段二的策略进行蒸馏融合到一起，获得一个新的策略。在这个策略的基础上我们在引入复杂地形提升策略的鲁棒性。

这个摘要没有体现使用绳驱动的必要性，请把下面这一点很好的融入摘要中。这也是文章创新的一个点
因为加入我们想把机器人做的很仿人的话必须控制整个身体的形态，其中最难的点在于如何在腿部排布这些电机还可以使得机器人像人腿形态一样，而借鉴仿生的思想的话，绳驱就像肌腱一样可以远端驱动我们的关节，但这也带来的一个问题，因为电机的扭矩通常是与体积成正比的。如果我们想完成爆发动作的话，绳驱应该怎么解决，我们的回答是电机耦合的方式，两个电机耦合在一起实现力量倍增的效果

请帮我写一下引言部分，下面是本文的摘要和相关文献的引言参考。我希望结合摘要部分，完成引言的编写符合RAL风格，整个脉络是，分析摔倒起身的问题和现状，绳驱的问题和现状以及目前的相关研究和解决方法，并且分析他们的不足和局限性，最后引出我们的方法，以及优点和创新点

另一方面，为实现更接近人类的全身运动形态，类人机器人需要在腿部实现高功率、轻量化且高度仿生的关节驱动布局。然而，传统集中式电机直驱方案难以在保持类人腿部几何结构的同时提供足够的爆发力。受生物肌腱系统启发，\textbf{绳驱动（tendon-driven）方案}能够实现远端电机驱动关节，使腿部结构更加仿人化，但单电机扭矩通常受体积与质量约束而难以满足高动态动作需求。为缓解这一矛盾，本文采用\textbf{电机耦合绳驱方案}，通过多电机协同驱动同一关节，实现等效扭矩放大，在保持仿生结构的同时满足爆发动作所需的动力性能。  

针对上述挑战，本章提出了一种面向\textbf{绳驱动双足机器人}的\textbf{分阶段起身学习与策略蒸馏融合框架}，实现从任意跌倒姿态到稳定站立的鲁棒恢复能力，并具备复杂地形适应性。具体而言，我们将起身任务分解为两个阶段：  

\textbf{阶段一}学习从任意跌倒姿态平滑过渡到统一的“起身初始姿态”，以降低姿态多样性与接触不确定性带来的学习难度；  

\textbf{阶段二}基于第四章提出的模仿学习全身控制框架，在电机耦合绳驱约束下训练从起身初始姿态到稳定站立的动态起身策略，在保证运动自然性的同时满足物理可行性与硬件约束。  

随后，我们采用\textbf{策略蒸馏}方法将阶段一与阶段二的策略融合为单一统一策略，使机器人无需显式阶段切换即可完成完整起身过程，从而提升运动连续性、实时可控性与部署友好性。进一步地，我们在融合策略基础上引入复杂地形训练，通过地形随机化与在线强化微调增强策略在斜坡、台阶、不平整地面等环境下的鲁棒性与泛化能力。  

我们在高保真仿真环境以及真实绳驱动双足机器人平台上进行了系统实验。结果表明，所提出的方法能够实现从任意姿态的跌倒恢复、坐起与站立，并在复杂地形下保持稳定与自然的运动表现，为真实场景下绳驱类人机器人的长期自主运行提供了可靠基础。  

\section{引言}
类人机器人由于其与人类高度相似的身体结构，被寄予在真实世界中执行多种人类日常动作的期望，包括行走、操作以及在失稳或跌倒后的自主恢复。近年来，随着硬件设计与控制算法的快速发展，类人机器人在双足行走、动态运动以及双臂操作等方面已取得显著进展。然而，一个更为基础的能力——\textbf{起身站立控制} \cite{43,17}——仍未得到充分研究。大多数现有系统都假设机器人从预先站立的姿态开始运动，这极大地限制了其在许多真实场景中的适用性，例如从坐姿过渡到站立，或在失去平衡后恢复站立。我们认为，突破这一起身站立能力将大幅拓展类人机器人的现实应用场景。为此，本文研究类人机器人如何在真实环境中从多样化姿态中学习站立起身。

一种经典的控制方法是通过基于模型的运动规划或轨迹优化来跟踪人工设计的运动轨迹 \cite{17,18,22,43}。尽管这些方法能够有效生成运动，但它们需要对分析模型进行大量调参，并且在存在外部扰动 \cite{29,23} 或执行器建模不准确 \cite{15} 的真实环境中往往表现不佳。此外，由于机器人上的实时优化计算开销较大，这类方法通常需要降低优化精度或将计算外包给外部计算设备 \cite{34,8}，但这两种折衷方案在实际应用中均存在明显局限。

强化学习（RL）为类人机器人运动与全身控制提供了一种有效的替代框架 \cite{36,13,4,53}，其优势在于对系统模型的依赖较弱。然而，与双足行走等可在一定程度上解耦上、下半身动力学的任务相比，RL 方式下的起身控制涉及高度动态且协同的全身运动。这一复杂动作包含时变接触点 \cite{17}、多阶段运动技能 \cite{29} 以及精确的角动量控制 \cite{11}，使得 RL 探索极具挑战性。尽管预定义运动轨迹可用于引导 RL 探索，但这些轨迹通常仅适用于特定地面姿态 \cite{35,36,51,12}，其在其他姿态下的可扩展性仍不明确。相反，在地面上从零开始采用广泛探索策略训练 RL 智能体，往往会产生剧烈且不稳定的运动，难以在真实机器人上部署 \cite{46}，尤其是对于具有大量关节和宽广运动范围的高自由度机器人。综上所述，利用 RL 学习姿态自适应且可在真实世界部署的起身控制仍是一个开放问题（见表~I）。



在完成起身任务的同时，我们还期望机器人具备与人类相似的整体形态特征，例如更为苗条的躯干和纤细的小腿，这对机器人本体结构设计提出了更高要求，需要在本体结构与传动方案上进行突破。

传统的直驱方案通过将高扭矩电机直接集成于关节处，实现了精确、可重复且易建模的关节控制，具有结构简单、控制可靠、带宽高、维护方便以及动力学建模相对明确等优势，因此在工业机器人和部分人形平台中得到了广泛应用。然而，为满足关节所需的峰值扭矩和刚度，直驱电机通常具有较大的体积和质量，这迫使驱动单元集中布置在四肢末端附近，进而导致关节尺寸显著增大、肢体惯量增加以及整体重量分布偏离躯干中心。相比之下，人体采用肌肉--肌腱远程分布式驱动机制，不仅能够实现弹性储能与力的远距离传递，还支持纤细、轻量且高效的肢体结构。由于缺乏类似的弹性与远程传力路径，直驱系统难以在保持高输出能力的同时兼顾仿人化的纤细外形与高能效特性。由此可见，尽管直驱方案在控制性能上具有显著优势，但其固有的物理与工程约束使其难以复现人体般紧凑、柔顺且高能效的身体形态。

另一方面，为实现更接近人类的全身运动形态，类人机器人需要在腿部关节中同时满足高功率输出、轻量化结构和高度仿生的几何布局。然而，传统集中式电机直驱方案难以在保持类人腿部纤细几何结构的同时提供足够的爆发力。受生物肌腱系统启发，\textbf{绳驱动（tendon-driven）方案}能够将电机布置在远端并通过绳索传递扭矩，从而使腿部结构更加仿人化。但单电机的输出扭矩通常受体积与质量限制，难以满足高动态动作（如快速起身、跳跃或冲击吸收）的需求。为缓解这一矛盾，本文采用\textbf{电机耦合绳驱方案}，通过多电机协同驱动同一关节，实现等效扭矩放大，在保持仿生结构优势的同时满足爆发动作所需的动力性能。


综上所述，当前研究存在三方面关键不足：  
(i) 缺乏能够处理\textbf{任意跌倒姿态}的统一起身策略；  
(ii) 缺乏专门面向\textbf{绳驱动双足机器人}的学习与控制框架；  
(iii) 端到端训练难以兼顾\textbf{样本效率、运动自然性与硬件可行性}。

针对上述挑战，本文提出了一种面向\textbf{绳驱动双足机器人}的\textbf{分阶段起身学习与策略蒸馏融合框架}。我们将起身任务分解为两个互补阶段：  
\begin{itemize}
  \item \textbf{阶段一：姿态统一}——学习从任意跌倒姿态平滑过渡到统一的“起身初始姿态”，以降低姿态多样性与接触不确定性带来的学习难度；
  \item \textbf{阶段二：动态起身}——基于第四章提出的模仿学习全身控制框架，在电机耦合绳驱约束下训练从起身初始姿态到稳定站立的动态起身策略，兼顾自然性与物理可行性。
\end{itemize}

随后，我们采用\textbf{策略蒸馏}方法将两阶段策略融合为单一统一策略，使机器人无需显式阶段切换即可完成完整起身过程，从而提升连续性、实时可控性与部署友好性。进一步地，我们在融合策略基础上引入复杂地形训练，通过地形随机化与在线强化微调增强策略在斜坡、台阶、不平整地面等环境下的鲁棒性与泛化能力。

我们在高保真仿真环境以及真实绳驱动双足机器人平台上进行了系统验证。实验结果表明，所提出的方法能够实现从任意姿态的跌倒恢复、坐起与站立，并在复杂地形下保持稳定与自然的运动表现，为真实场景下绳驱类人机器人的长期自主运行提供了可靠基础。

\section{方法}
\subsection{绳驱动机器人运动学建模}
本文所采用的双足类人机器人平台如图~\ref{fig:platform} 所示。该机器人身高约 1.7,m，整机质量约 30,kg，总计具有 28 个自由度（DOFs），其中双腿各包含 6 个自由度，共 12 个自由度分布于下肢系统。每条腿由髋关节的 3 个自由度（俯仰、外展/内收及旋转）、膝关节的 1 个俯仰自由度，以及踝关节的 2 个自由度（俯仰与滚转）构成，能够支持复杂的全身动态运动与多接触交互行为。

为降低远端肢体质量与转动惯量、提升整体动态响应性能，机器人关键下肢关节采用了腱驱动（tendon-driven）传动机制。相比传统直驱方案，腱驱动系统能够实现电机远置布局，将高扭矩直流电机集中安装于靠近质心（Center of Mass, COM）的位置，从而有效减小腿部末端质量并降低摆动惯量。这种结构设计不仅显著提升了运动机动性，还增强了系统在高速动态任务中的稳定性。

腱驱动机制具备轻量化传动结构、优良的力控制特性以及快速动态响应等优势，因此已被广泛应用于高性能机器人与仿生机械臂系统中 \cite{ref20,ref21}。在对低质量、高顺应性以及高扭矩质量比有严格要求的应用场景下，该驱动方式能够实现更加灵活、安全且高效的运动控制。

在机械实现层面，电机输出通过直径为 1.5,mm 的高强度钢缆传递至膝关节与踝关节。钢缆材料具有优异的抗拉强度与抗疲劳性能，能够满足高频动态加载需求。整套腱驱动系统采用双向缠绕结构，并集成内置张力调节机构，以有效抑制钢缆松弛与回程间隙问题，从而保证稳定的扭矩传递与低回差（low backlash）的关节控制性能。得益于该结构优化设计，单条腿的结构质量降低至 3.6,kg 以下，在保持高输出能力的同时实现了显著的轻量化效果。

控制系统方面，机器人运行于基于 Linux 的实时控制平台上。所有关节均配备高精度绝对值编码器，并统一采用位置控制模式，实现高带宽闭环控制。在复杂接触与高动态任务条件下，该系统能够保持良好的实时性与控制精度，为后续高动态起身控制策略的实现提供了坚实的硬件基础。

\subsection{膝关节扭矩映射关系}

如图~\ref{fig:platform} 所示，膝关节采用远程电机驱动的两级腱驱动传动结构。驱动电机安装于大腿上部，通过钢缆与导向滑轮构成传动链路，将电机输出扭矩传递至膝关节输出滑轮，实现关节力矩输出。

在理想无滑移、无弹性变形条件下，根据几何约束关系与力矩平衡关系，单电机与膝关节之间的扭矩比例系数定义为

\begin{equation}
    \tau^{\mathrm{knee}}_j
    =
    \frac{r^{\mathrm{knee}}_m}{r^{\mathrm{knee}}_j}
    \,
    \tau^{\mathrm{knee}}_m ,
\label{eq:knee_torque_relation}
\end{equation}
其中 $r^{\mathrm{knee}}_m$ 与 $r^{\mathrm{knee}}_j$ 分别表示电机输入滑轮与膝关节输出滑轮的有效半径，$\tau^{\mathrm{knee}}_m$ 与 $\tau^{\mathrm{knee}}_j$ 分别表示电机侧与关节侧扭矩。用比例系数$k$来刻画单电机驱动下的电机-关节扭矩关系。

在双电机耦合驱动结构中，两台电机通过钢缆共同作用于膝关节滑轮。
因此，双电机耦合驱动下的膝关节输出扭矩可表示为
\begin{equation}
\tau^{\mathrm{knee}}_j
=
a^{\mathrm{knee}}\,k\,\tau_{m,1}
+
b^{\mathrm{knee}}\,k\,\tau_{m,2}.
\label{eq:knee_coupled}
\end{equation}

考虑绕绳方向与正方向约定的影响，引入方向系数
$a^{\mathrm{knee}},b^{\mathrm{knee}} \in \{+1,-1\},$
分别表示电机 $1$ 与电机 $2$ 的输出方向相对于膝关节正方向的一致性。

上述关系表明，在耦合结构下，关节侧扭矩等于各电机输出扭矩经传动比例换算后的线性叠加，其符号由钢缆绕行拓扑决定。由于两台电机可同时作用于同一关节滑轮，关节侧的等效输出能力等于多电机扭矩的协同叠加，从而在不增加单台电机体积与质量的前提下显著提升关节的最大可输出扭矩。


% 与传统直驱结构相比，该两级腱驱方案具有以下优势：
% \begin{itemize}
%     \item 显著降低小腿远端质量与转动惯量；
%     \item 提高单位质量扭矩输出比，实现多电机协同增扭；
%     \item 结构形式更加接近生物肌腱驱动模式。
% \end{itemize}
% 综上，该双电机耦合腱驱膝关节结构在实现高扭矩输出的同时，有效兼顾了轻量化与结构紧凑性的设计需求。



\subsection{踝关节扭矩映射关系}

为进一步减轻远端肢体质量并提升整体驱动效率，本文提出一种膝关节与踝关节耦合的三级腱驱动传动结构。该结构通过级联滑轮与钢缆构建多级动力传输路径，使单个电机能够在机械结构上同时参与膝关节与踝关节的驱动，从而实现更高的功率密度与更紧凑的布局设计。

其动力传递路径如下：

\begin{enumerate}
    \item 第一级传动：电机输出经钢缆传递至膝关节输出滑轮；
    \item 第二级传动：膝关节输出滑轮通过级联钢缆与踝关节输入滑轮连接；
    \item 第三级传动：踝关节滑轮将扭矩传递至足部执行结构，形成完整动力传输链路。
\end{enumerate}


在理想无弹性变形与无摩擦损失条件下，单级滑轮传动的电机—关节扭矩关系为
\begin{equation}
    \tau_j
    =
    \frac{r_m}{r_j}
    \tau_m ,
\end{equation}
其中 $r_m$ 与 $r_j$ 分别表示输入滑轮与输出滑轮的有效半径。

对于膝—踝级联结构，电机扭矩需依次经过膝关节与踝关节两级传动。因此，其整体等效扭矩比例系数可表示为两级半径比的乘积：
\begin{equation}
G
=
\frac{
r^{\mathrm{knee}}_m \, r^{\mathrm{ankle}}_m
}{
r^{\mathrm{knee}}_j \, r^{\mathrm{ankle}}_j
}.
\label{eq:G_total}
\end{equation}

式中 $r^{\mathrm{knee}}_m$、$r^{\mathrm{knee}}_j$ 分别为膝关节级传动中的电机侧与关节侧滑轮半径，
$r^{\mathrm{ankle}}_m$、$r^{\mathrm{ankle}}_j$ 分别为踝关节级传动中的电机侧与关节侧滑轮半径。
比例系数 $G$ 刻画了三级级联结构下电机侧扭矩到踝关节侧扭矩的整体放大倍数。

在双电机耦合驱动结构中，两台电机共同作用于踝关节传动链路。

因此，耦合驱动条件下踝关节输出扭矩可表示为
\begin{equation}
\tau^{\mathrm{ankle}}_j
=
a^{\mathrm{ankle}}\,G\,\tau_{m,1}
+
b^{\mathrm{ankle}}\,G\,\tau_{m,2}.
\label{eq:ankle_coupled}
\end{equation}
考虑绕绳方向与正方向约定的影响，引入方向系数
$
a^{\mathrm{ankle}},b^{\mathrm{ankle}} \in \{+1,-1\},
$
分别表示电机 $1$ 与电机 $2$ 的输出方向相对于踝关节正方向的一致性。
上述关系表明，在三级级联结构中，踝关节侧扭矩等于两台电机输出扭矩经整体传动比例 $G$ 放大后的线性叠加，其符号由钢缆绕行拓扑决定。通过多电机协同输出机制，在不增加单台电机体积与质量的前提下，可显著提升踝关节的最大可输出扭矩能力。

\subsection{关节-电机扭矩映射关系}

由式~\ref{eq:knee_coupled} 与式~\ref{eq:ankle_coupled} 可将耦合驱动系统统一写为矩阵形式：
\begin{equation}
\boldsymbol{\tau}_j
=
\mathbf{J}
\boldsymbol{\tau}_m,
\quad
\mathbf{J}
=
\begin{bmatrix}
a^{\mathrm{knee}}\,k & b^{\mathrm{knee}}\,k \\
a^{\mathrm{ankle}}\,G & b^{\mathrm{ankle}}\,G
\end{bmatrix},
\label{eq:torque_mapping}
\end{equation}
其中
\[
\boldsymbol{\tau}_j =
\begin{bmatrix}
\tau^{\mathrm{knee}}_j \\
\tau^{\mathrm{ankle}}_j
\end{bmatrix}
\]
表示关节侧扭矩向量，
\[
\boldsymbol{\tau}_m =
\begin{bmatrix}
\tau_{m,1} \\
\tau_{m,2}
\end{bmatrix}
\]
表示电机侧扭矩向量，
$\mathbf{J}$ 为电机—关节扭矩映射矩阵，其元素由传动比及绕绳方向符号共同决定。

当矩阵 $\mathbf{J}$ 满足可逆条件（即 $\det(\mathbf{J}) \neq 0$）时，可进一步得到逆映射关系：
\begin{equation}
\boldsymbol{\tau}_m
=
\mathbf{J}^{-1}
\boldsymbol{\tau}_j.
\label{eq:inverse_mapping}
\end{equation}

基于式~\ref{eq:torque_mapping} 与式~\ref{eq:inverse_mapping}，可以在强化学习训练过程中将关节侧控制量映射至电机侧，从而显式引入电机物理约束。具体而言，通过
\[
\boldsymbol{\tau}_m = \mathbf{J}^{-1}\boldsymbol{\tau}_j
\]
可实时计算对应的电机输出扭矩，并在策略优化过程中施加幅值限制
\[
|\tau_{m,i}| \le \tau_{m,i}^{\max},
\]
以保证控制信号始终满足电机额定能力。

同时，由于映射矩阵 $\mathbf{J}$ 明确刻画了传动比与方向耦合关系，在满足电机侧约束的前提下，可确保关节侧获得其物理可实现的最大输出扭矩。因此，该映射关系不仅建立了电机侧与关节侧之间的物理一致性约束，而且为训练阶段实现“电机安全约束”与“关节性能最大化”提供了理论基础。

从几何角度来看，矩阵 $\mathbf{J}$ 定义了电机扭矩空间与关节扭矩空间之间的线性映射关系，而逆映射刻画了在给定关节任务需求下的电机负载分配规律。因此，在策略训练过程中直接在电机空间施加约束，相较于仅在关节空间进行裁剪，更符合真实驱动系统的物理特性。

\subsection{策略训练}
% \subsubsection{跌倒恢复行为策略}
% #大论文版本
% \subsubsection{跌倒恢复行为策略}
% 在类人机器人强化学习中，奖励函数的设计通常是实现复杂行为的关键难点。既有工作~\cite{9,13,32} 为了弥补参考轨迹中的噪声与物理不一致性，往往引入大量人工构造的正则项（例如摆脚时间约束、接触持续时间约束等）。然而，此类奖励项通常依赖任务特定经验设计，调参过程复杂且对场景变化高度敏感，难以推广至更复杂或多接触的任务场景。对于跌倒恢复任务而言，由于涉及多阶段接触转换与更为稀疏的任务目标信号，奖励设计的难度进一步增加。

% 为缓解上述问题，我们采用基于运动学参考轨迹跟踪的强化学习框架。该方法通过引入高质量的参考动作，将复杂任务目标转化为轨迹跟踪问题，并利用强化学习弥合运动学与动力学之间的差距。具体而言，通过训练底层控制策略，使其在物理约束与接触动力学条件下精确跟踪参考轨迹，从而将纯运动学动作转换为物理可实现的动态行为。这种“参考驱动 + 物理适配”的学习方式已被证明能够显著降低奖励设计复杂度，并具备良好的仿真到真实系统的零样本迁移（zero-shot transfer）能力。

% BeyondMimic~\cite{33} 的研究表明，当参考轨迹质量足够高且噪声较低~\cite{34} 时，仅依赖极简形式的跟踪奖励即可实现稳定且高质量的策略学习。在此基础上，我们构建跌倒恢复行为策略：首先通过动作捕捉系统采集人类起身动作数据，经由运动重定向算法映射至机器人关节空间，生成物理一致的参考轨迹；随后基于上述极简奖励结构训练强化学习策略，使机器人能够在多接触条件下稳定完成起身动作。

\subsubsection{跌倒恢复行为策略}
% # RAL版本
在类人机器人强化学习中，复杂行为往往依赖精细的奖励设计。既有工作~\cite{9,13,32} 通常引入大量人工正则项（如摆脚时间、接触持续时间等）以补偿参考轨迹中的噪声或物理不一致性。然而，这类奖励设计依赖经验调参，泛化能力有限。对于跌倒恢复任务，由于涉及多阶段接触与较为稀疏的目标信号，奖励构造更加困难。

通过跟踪运动学参考轨迹的方法，可以很好的解决繁重的奖励设计任务，而采用强化学习（RL）又可以弥合运动学与动力学之间的差距，通过训练一个底层策略，将这些轨迹转换为物理上可实现的动作，从而实现从仿真到真实硬件的零样本迁移（zero-shot transfer）。BeyondMimic~\cite{33} 表明，当参考轨迹足够干净~\cite{34} 时，仅使用极简奖励函数即可实现高质量跟踪，我们在此基础上训练起身策略。利用通过动捕设备采集的起身动作，通过重定向后作为参考动作来训练。



\subsubsection{姿态过渡策略}
在真实环境中，机器人跌倒后的初始状态具有高度不确定性，可能呈现任意朝向及复杂关节构型。当当前状态与起身参考轨迹的初始帧偏差过大时，直接使用跟踪策略往往难以收敛。因此，我们额外训练一个姿态过渡策略，用于将随机跌倒姿态引导至起身参考动作的初始帧，从而为后续跟踪策略提供稳定初始化。

该策略的训练方式与起身策略一致，但显著扩大初始状态的随机范围，包括根姿态与关节角度的随机化。

\paragraph{随机根姿态初始化}

为随机化跌倒后的朝向，我们对根部偏航角采样
\begin{equation}
\theta \sim \mathcal{U}(0, 2\pi),
\end{equation}
并构造绕 $z$ 轴的随机四元数
\begin{equation}
\mathbf{q}_{\text{rand}} =
\left[
\cos\frac{\theta}{2},\;
0,\;
0,\;
\sin\frac{\theta}{2}
\right].
\end{equation}

由于仿真中根姿态的坐标系定义与参考动作（motion reference）采用的根坐标系存在一个固定的常量旋转偏差，
我们引入对齐四元数 $\mathbf{q}_{\text{fix}}$（常量），并按四元数乘法进行坐标系对齐：
\begin{equation}
\mathbf{q}_{\text{root}} = \mathbf{q}_{\text{fix}} \otimes \mathbf{q}_{\text{rand}}.
\end{equation}

本文实现中 $\mathbf{q}_{\text{fix}}$ 取为
$
\mathbf{q}_{\text{fix}} = [0.5,\,-0.5,\,0.5,\,0.5],
$
其作用是将随机偏航后的根姿态统一映射到参考动作所使用的坐标系约定下。


\paragraph{随机关节角初始化}

设关节物理限位为 $\mathbf{q}_{\min}$ 与 $\mathbf{q}_{\max}$，则初始关节角从缩放后的区间中均匀采样：

\begin{equation}
\mathbf{q}_0 \sim 
\mathcal{U}
\left(
0.4\,\mathbf{q}_{\min},
\; 0.4\,\mathbf{q}_{\max}
\right).
\end{equation}

该设计允许机器人在较大姿态扰动范围内进行恢复训练，同时避免过度接近关节极限。
姿态过渡策略的目标是将当前状态引导至起身参考轨迹的第一帧。记参考轨迹初始状态为 $(\mathbf{q}^{\text{ref}}_0, \mathbf{R}^{\text{ref}}_0)$，则过渡阶段的跟踪目标为：

\begin{equation}
\mathcal{L}_{\text{transition}} =
\|\mathbf{q} - \mathbf{q}^{\text{ref}}_0\|^2
+
d\big(\mathbf{R}, \mathbf{R}^{\text{ref}}_0\big),
\end{equation}

其中 $d(\cdot,\cdot)$ 表示姿态误差度量。


\subsection{策略训练}
\subsubsection{观测}
我们设计了一个极简的本体感觉观测空间，如下所示。在该设定下，智能体仅依靠自身感知来完成任务

\begin{itemize}
    \item \textbf{参考动作（Reference Motion）}：参考关节位置/速度，参考骨盆位置/姿态误差；
    \item \textbf{本体感觉（Proprioception）}：骨盆线速度/角速度，关节位置/速度；
    \item \textbf{上一时刻动作（Previous Action）}：策略在上一时间步输出的动作。
\end{itemize}

对于快速敏捷动作（此时状态估计不可靠），我们屏蔽骨盆线性位置误差与线速度项。

\subsubsection{奖励函数}
为体现高质量参考的优势并避免复杂调参，我们仅使用五项奖励：

\begin{itemize}
    \item \textbf{身体跟踪（Body Tracking）}：采用 DeepMimic 风格的跟踪项，约束身体位置、姿态、线速度与角速度；
    \item \textbf{物体跟踪（Object Tracking，若适用）}：采用 DeepMimic 风格的物体位置与姿态跟踪项；
    \item \textbf{动作变化率（Action Rate）}：惩罚动作的剧烈变化；
    \item \textbf{软关节限位（Soft Joint Limit）}：惩罚关节超过物理限位；
    \item \textbf{自碰撞（Self-Collision）}：当任一身体部位的自碰撞力超过 1\,N 时施加二值惩罚。
\end{itemize}

我们直接使用文献~\cite{33} 中的权重与超参数设置，无需额外调参。对于物体跟踪项，其超参数与身体跟踪项保持一致。

\subsubsection{终止条件}
当身体跟踪误差过大时终止训练回合~\cite{33}。对于涉及物体的移动与操作任务，当物体相对于参考轨迹的偏差超过 1.0\,m 或姿态偏差超过 $45^\circ$ 时终止回合。该终止条件仅在策略已达到合理身体跟踪性能后启用。

\subsubsection{域随机化（Domain Randomization）}
为提升单一参考动作在不同物体属性下的泛化能力，我们对物体物理参数进行随机化，包括：质量（0.1–2\,kg）、质心位置（$\pm0.08$\,m）、转动惯量（50\%–150\%）。

对于机器人本体，与以往工作中使用大量随机项（如随机力注入（RFI）、电机 PD 参数扰动、动作延迟等）不同，我们仅采用以下四项随机化：

\begin{itemize}
    \item \textbf{躯干质心位置}：$x$ 方向 $\pm0.025$\,m，$y$ 方向 $\pm0.05$\,m，$z$ 方向 $\pm0.075$\,m；
    \item \textbf{关节默认位置}：$\pm0.01$\,rad；
    \item \textbf{随机扰动（Random Push）}：线速度 0.3\,m/s，角速度 0.78\,rad/s，持续 1–3\,s；
    \item \textbf{观测噪声}：姿态（Rot6D 表示）$\pm0.05$，线速度 $\pm0.5$\,m/s，角速度 $\pm0.2$\,rad/s，关节位置 $\pm0.01$\,rad，关节速度 $\pm0.5$\,rad/s。
\end{itemize}


4.策略融合
在行为蒸馏过程中，我们采用 DAgger（Chen et al. 2020；Ross, Gordon, and Bagnell 2011）将不同的行为知识蒸馏到一个基于混合专家模型（Mixture-of-Experts, MoE）的多行为策略 $\pi_d$ 中，从而消除由不同奖励函数导致的梯度冲突问题。  

MoE 模块能够自动分配不同的专家来学习不同的行为，使策略能够利用这些先验知识，在后续的强化学习微调阶段实现高效的多行为提升与多地形适应能力。在训练过程中，机器人被初始化为跌倒或站立姿态，并根据当前需要执行的行为，由相应的教师策略 $\pi_b^r$ 或 $\pi_b^w$ 进行监督学习。多行为策略 $\pi_d$ 的损失函数定义为：  

% \begin{equation}
% \mathcal{L}_{\pi_d}(s_t)=
% \begin{cases}
% \mathbb{E}_{s_t,\pi_d,\pi_b^r}
% \left[\|a_t^{\pi_d}-a_t^{\pi_b^r}\|_2^2\right], & s_t\in \mathcal{S}_r,\\[6pt]
% \mathbb{E}_{s_t,\pi_d,\pi_b^w}
% \left[\|a_t^{\pi_d}-a_t^{\pi_b^w}\|_2^2\right], & s_t\in \mathcal{S}_w,
% \end{cases}
% \tag{4}
% \end{equation}

其中 $a_t^{\pi_d}$、$a_t^{\pi_b^r}$ 和 $a_t^{\pi_b^w}$ 分别从对应的策略中采样得到，$\mathcal{S}_r$ 和 $\mathcal{S}_w$ 分别表示站立恢复和行走对应的状态空间。  

蒸馏过程采用与行为特定策略训练相同的域随机化设置，而 $\pi_d$ 仅以本体感知 $s_t^{\text{prop}}$ 作为输入。该蒸馏过程不仅将多种基础行为整合到单一策略中，同时还分别提升了各个行为的性能。具体而言，$\pi_d$ 展现出更鲁棒的行走能力，因为它能够从接近跌倒的姿态中恢复；同时，在完成站立恢复后能够形成更加自然的站立姿态，从而实现更平滑的行走过渡。  

